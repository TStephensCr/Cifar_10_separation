{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TStephensCr/Cifar_10_separation/blob/main/cifar_10_separation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE7oyG0wv6e0"
      },
      "source": [
        "# Separazione di immagini Cifar10\n",
        "\n",
        "Il modello prende in input una immagine ottenuta come media di due campioni random presi da Cifar10, e deve predirre le categorie delle due componenti.\n",
        "\n",
        "La prima immagine appartiene alle prime 5 categorie (airplane, automobile, bird, cat, deer), mentre la seconda appartiene alle restanti (dog, frog, horse, ship, truck). Il modello deve restituire due label, ognuna in un range di 5 valori.\n",
        "\n",
        "La metrica con cui valutare il modello è la seguente: calcolate l'accuratezza della classificazione per le due immagini componenti, e poi fatene la media.\n",
        "\n",
        "La metrica deve essere valutata su 10000 input generati da dati di test. Ripetete il calcolo 10 volte e misurate la deviazione standard, che deve essere riportata.\n",
        "\n",
        "Nel seguito si fornisce un generatore dei dati e qualche esempio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USdmzjiO0W6D"
      },
      "source": [
        "#Preparazione dei dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjnh5XP0Sq4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRYiW2ipukZF"
      },
      "outputs": [],
      "source": [
        "(cifar10_x_train, cifar10_y_train), (cifar10_x_test, cifar10_y_test) = cifar10.load_data()\n",
        "assert cifar10_x_train.shape == (50000, 32, 32, 3)\n",
        "assert cifar10_x_test.shape == (10000, 32, 32, 3)\n",
        "assert cifar10_y_train.shape == (50000, 1)\n",
        "assert cifar10_y_test.shape == (10000, 1)\n",
        "\n",
        "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
        "\n",
        "cifar10_x_train = (cifar10_x_train/255.).astype(np.float32)\n",
        "cifar10_x_test = (cifar10_x_test/255.).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkiGnU4d0k4d"
      },
      "source": [
        "Separiamo le immagini in due gruppi, in relazione alla loro etichetta.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dpey42Vo07Yb"
      },
      "outputs": [],
      "source": [
        "cond_1 = cifar10_y_train[:,0] < 5\n",
        "cifar10_x_train_1 = cifar10_x_train[cond_1]\n",
        "cifar10_y_train_1 = cifar10_y_train[cond_1]\n",
        "\n",
        "cond_2 = cifar10_y_train[:,0] >= 5\n",
        "cifar10_x_train_2 = cifar10_x_train[cond_2]\n",
        "cifar10_y_train_2 = cifar10_y_train[cond_2]\n",
        "\n",
        "cond_1_test = cifar10_y_test[:,0] < 5\n",
        "cifar10_x_test_1 = cifar10_x_test[cond_1_test]\n",
        "cifar10_y_test_1 = cifar10_y_test[cond_1_test]\n",
        "\n",
        "cond_2_test = cifar10_y_test[:,0] >= 5\n",
        "cifar10_x_test_2 = cifar10_x_test[cond_2_test]\n",
        "cifar10_y_test_2 = cifar10_y_test[cond_2_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmLYNuR-0s0m"
      },
      "source": [
        "Adesso possiamo definire il generatore. In input abbiamo due datasets (X1,X2), le etichette corrispondenti (Y1,Y2) e una batchsize.\n",
        "\n",
        "Il generatore resituisce x_data, y_data, dove\n",
        "\n",
        "*   x_data è una batch di immagini ottenute come media di campioni random in X1 and X2\n",
        "*   y_data è una coppia di batch di etichette relative alle immagini componenti, espresse in formato categorico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Y5Zpv5fw2hd"
      },
      "outputs": [],
      "source": [
        "def datagenerator(X1,X2,Y1,Y2,batchsize):\n",
        "  size1 = X1.shape[0]\n",
        "  size2 = X2.shape[0]\n",
        "  Y1_cat = tf.keras.utils.to_categorical(Y1, num_classes=5)\n",
        "  Y2_cat = tf.keras.utils.to_categorical(Y2-5, num_classes=5)\n",
        "\n",
        "  def augment_image(image): # Funzione di data augmentation, ottenuta ruotando le immagini\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    image = tf.image.rot90(image, k=np.random.randint(0, 4))\n",
        "    return image\n",
        "\n",
        "  while True:\n",
        "    num1 = np.random.randint(0, size1, batchsize)\n",
        "    num2 = np.random.randint(0, size2, batchsize)\n",
        "    x_data = (X1[num1] + X2[num2]) / 2.0\n",
        "    x_data = np.array([augment_image(x).numpy() for x in x_data])\n",
        "    y_data = [Y1_cat[num1],Y2_cat[num2]]\n",
        "\n",
        "    yield x_data, y_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9lf3TuP2pdQ"
      },
      "source": [
        "Instanziamo un generatore su Cifar10 con batchsize=1, e testiamone il comportamento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29TldJ6-720b"
      },
      "outputs": [],
      "source": [
        "datagen = datagenerator(cifar10_x_train_1,cifar10_x_train_2,cifar10_y_train_1,cifar10_y_train_2,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1DrJVzI3ysV"
      },
      "source": [
        "Generiamo un esempio, mostriamo l'immagine che deve essere presa in input dal modello, e stampiamo le categorie delle due componenti sovrapposte.\n",
        "\n",
        "Potete rirpetere l'esecuzione della cella per mostrare nuovi esempi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "qL1sMtjG8VmG",
        "outputId": "d23116e8-8b17-4caa-c803-f45a92808752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first: cat, second = truck\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x79eb8515d1e0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "x, y = next(datagen)\n",
        "\n",
        "print(\"first: {}, second = {}\".format(classes[np.argmax(y[0][0])],classes[np.argmax(y[1][0])+5]))\n",
        "#print(np.min(x[0]),np.max(x[0]))\n",
        "plt.imshow(x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5lzBotwL5QN"
      },
      "source": [
        "# Valutazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_p4UuG1QF8t"
      },
      "source": [
        "Dfiniamo innanzi tutto il generatore di testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQo8_6w-L4WY",
        "outputId": "5c046fa1-4468-415a-bbb5-211236d913b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "testgen = datagenerator(cifar10_x_test_1,cifar10_x_test_2,cifar10_y_test_1,cifar10_y_test_2,10000)\n",
        "\n",
        "eval_samples_x, eval_samples_y = next(testgen)\n",
        "print(eval_samples_x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MiLnkKROGCD"
      },
      "source": [
        "Segue il modello."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GllTEtPN_xv"
      },
      "outputs": [],
      "source": [
        "def build_model():\n",
        "    input_layer = layers.Input(shape=(32, 32, 3))\n",
        "\n",
        "    # First convolutional block\n",
        "    conv1 = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(input_layer)\n",
        "    norm1 = layers.BatchNormalization()(conv1)\n",
        "    conv2 = layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(norm1)\n",
        "    norm2 = layers.BatchNormalization()(conv2)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(norm2)\n",
        "\n",
        "    # Second convolutional block\n",
        "    conv3 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(pool1)\n",
        "    norm3 = layers.BatchNormalization()(conv3)\n",
        "    conv4 = layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(norm3)\n",
        "    norm4 = layers.BatchNormalization()(conv4)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(norm4)\n",
        "\n",
        "    # Residual connection block\n",
        "    shortcut = layers.Conv2D(128, kernel_size=(1, 1), strides=(1, 1), padding='same')(pool2)\n",
        "    conv5 = layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(pool2)\n",
        "    norm5 = layers.BatchNormalization()(conv5)\n",
        "    conv6 = layers.Conv2D(128, kernel_size=(3, 3), activation=None, padding='same')(norm5)\n",
        "    norm6 = layers.BatchNormalization()(conv6)\n",
        "    add_layer = layers.Add()([norm6, shortcut])\n",
        "    activation_layer = layers.ReLU()(add_layer)\n",
        "    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(activation_layer)\n",
        "\n",
        "    # Global pooling\n",
        "    global_pool = layers.GlobalAveragePooling2D()(pool3)\n",
        "\n",
        "    # Fully connected layers\n",
        "    dense1 = layers.Dense(512, activation='relu')(global_pool)\n",
        "    dropout_layer = layers.Dropout(0.5)(dense1)\n",
        "\n",
        "    # Output layers\n",
        "    out1 = layers.Dense(5, activation='softmax', name='class_output1')(dropout_layer)\n",
        "    out2 = layers.Dense(5, activation='softmax', name='class_output2')(dropout_layer)\n",
        "\n",
        "    # Model assembly and compilation\n",
        "    net = Model(inputs=input_layer, outputs=[out1, out2])\n",
        "    net.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=[['accuracy'], ['accuracy']]\n",
        "    )\n",
        "\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gomFTuuDOy8A"
      },
      "outputs": [],
      "source": [
        "# Funzione per richiamare e valutare il modello\n",
        "def assess_model(trained_model):\n",
        "    sample_inputs, sample_labels = next(testgen)\n",
        "    predictions = trained_model(sample_inputs)\n",
        "    acc1 = np.argmax(predictions[0], axis=1) == sample_labels[0][:, 0]\n",
        "    acc2 = np.argmax(predictions[1], axis=1) == sample_labels[1][:, 0]\n",
        "    return (np.mean(acc1) + np.mean(acc2)) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4AL2M6yjJno",
        "outputId": "71270d01-d07f-4f93-87ed-8201d7fd6095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10ms/step - class_output1_accuracy: 0.6209 - class_output1_loss: 0.9908 - class_output2_accuracy: 0.6677 - class_output2_loss: 0.8678 - loss: 1.8586 - val_class_output1_accuracy: 0.7190 - val_class_output1_loss: 0.7094 - val_class_output2_accuracy: 0.7925 - val_class_output2_loss: 0.5561 - val_loss: 1.2664 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.7468 - class_output1_loss: 0.6472 - class_output2_accuracy: 0.8281 - class_output2_loss: 0.4655 - loss: 1.1127 - val_class_output1_accuracy: 0.7727 - val_class_output1_loss: 0.5908 - val_class_output2_accuracy: 0.8539 - val_class_output2_loss: 0.4023 - val_loss: 0.9937 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.8046 - class_output1_loss: 0.5087 - class_output2_accuracy: 0.8719 - class_output2_loss: 0.3477 - loss: 0.8564 - val_class_output1_accuracy: 0.8079 - val_class_output1_loss: 0.5144 - val_class_output2_accuracy: 0.8712 - val_class_output2_loss: 0.3542 - val_loss: 0.8691 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.8340 - class_output1_loss: 0.4301 - class_output2_accuracy: 0.8985 - class_output2_loss: 0.2802 - loss: 0.7103 - val_class_output1_accuracy: 0.8219 - val_class_output1_loss: 0.4586 - val_class_output2_accuracy: 0.8930 - val_class_output2_loss: 0.2992 - val_loss: 0.7582 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.8661 - class_output1_loss: 0.3600 - class_output2_accuracy: 0.9171 - class_output2_loss: 0.2319 - loss: 0.5918 - val_class_output1_accuracy: 0.8501 - val_class_output1_loss: 0.4103 - val_class_output2_accuracy: 0.9005 - val_class_output2_loss: 0.2897 - val_loss: 0.7003 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.8827 - class_output1_loss: 0.3156 - class_output2_accuracy: 0.9319 - class_output2_loss: 0.1911 - loss: 0.5068 - val_class_output1_accuracy: 0.8268 - val_class_output1_loss: 0.4853 - val_class_output2_accuracy: 0.8808 - val_class_output2_loss: 0.3489 - val_loss: 0.8351 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.8987 - class_output1_loss: 0.2727 - class_output2_accuracy: 0.9415 - class_output2_loss: 0.1636 - loss: 0.4363 - val_class_output1_accuracy: 0.8536 - val_class_output1_loss: 0.4221 - val_class_output2_accuracy: 0.9089 - val_class_output2_loss: 0.2740 - val_loss: 0.6961 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9140 - class_output1_loss: 0.2312 - class_output2_accuracy: 0.9514 - class_output2_loss: 0.1371 - loss: 0.3684 - val_class_output1_accuracy: 0.8542 - val_class_output1_loss: 0.4129 - val_class_output2_accuracy: 0.9094 - val_class_output2_loss: 0.2848 - val_loss: 0.6980 - learning_rate: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9234 - class_output1_loss: 0.2032 - class_output2_accuracy: 0.9591 - class_output2_loss: 0.1147 - loss: 0.3179 - val_class_output1_accuracy: 0.8308 - val_class_output1_loss: 0.5255 - val_class_output2_accuracy: 0.8692 - val_class_output2_loss: 0.4247 - val_loss: 0.9507 - learning_rate: 0.0010\n",
            "Epoch 10/20\n",
            "\u001b[1m1559/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - class_output1_accuracy: 0.9311 - class_output1_loss: 0.1890 - class_output2_accuracy: 0.9639 - class_output2_loss: 0.1029 - loss: 0.2919\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9311 - class_output1_loss: 0.1890 - class_output2_accuracy: 0.9639 - class_output2_loss: 0.1029 - loss: 0.2919 - val_class_output1_accuracy: 0.8595 - val_class_output1_loss: 0.4590 - val_class_output2_accuracy: 0.9145 - val_class_output2_loss: 0.2852 - val_loss: 0.7446 - learning_rate: 0.0010\n",
            "Epoch 11/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9590 - class_output1_loss: 0.1172 - class_output2_accuracy: 0.9801 - class_output2_loss: 0.0581 - loss: 0.1753 - val_class_output1_accuracy: 0.8768 - val_class_output1_loss: 0.4311 - val_class_output2_accuracy: 0.9226 - val_class_output2_loss: 0.2837 - val_loss: 0.7151 - learning_rate: 3.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - class_output1_accuracy: 0.9751 - class_output1_loss: 0.0687 - class_output2_accuracy: 0.9893 - class_output2_loss: 0.0321 - loss: 0.1007 - val_class_output1_accuracy: 0.8786 - val_class_output1_loss: 0.4527 - val_class_output2_accuracy: 0.9262 - val_class_output2_loss: 0.3136 - val_loss: 0.7666 - learning_rate: 3.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m1560/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - class_output1_accuracy: 0.9812 - class_output1_loss: 0.0550 - class_output2_accuracy: 0.9921 - class_output2_loss: 0.0248 - loss: 0.0798\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9812 - class_output1_loss: 0.0550 - class_output2_accuracy: 0.9921 - class_output2_loss: 0.0248 - loss: 0.0798 - val_class_output1_accuracy: 0.8737 - val_class_output1_loss: 0.4771 - val_class_output2_accuracy: 0.9231 - val_class_output2_loss: 0.3338 - val_loss: 0.8115 - learning_rate: 3.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9887 - class_output1_loss: 0.0357 - class_output2_accuracy: 0.9960 - class_output2_loss: 0.0143 - loss: 0.0500 - val_class_output1_accuracy: 0.8789 - val_class_output1_loss: 0.5022 - val_class_output2_accuracy: 0.9263 - val_class_output2_loss: 0.3348 - val_loss: 0.8376 - learning_rate: 9.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9934 - class_output1_loss: 0.0243 - class_output2_accuracy: 0.9966 - class_output2_loss: 0.0117 - loss: 0.0361 - val_class_output1_accuracy: 0.8781 - val_class_output1_loss: 0.5247 - val_class_output2_accuracy: 0.9274 - val_class_output2_loss: 0.3494 - val_loss: 0.8745 - learning_rate: 9.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m1558/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - class_output1_accuracy: 0.9939 - class_output1_loss: 0.0207 - class_output2_accuracy: 0.9969 - class_output2_loss: 0.0106 - loss: 0.0312\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9939 - class_output1_loss: 0.0207 - class_output2_accuracy: 0.9969 - class_output2_loss: 0.0106 - loss: 0.0312 - val_class_output1_accuracy: 0.8777 - val_class_output1_loss: 0.5522 - val_class_output2_accuracy: 0.9267 - val_class_output2_loss: 0.3593 - val_loss: 0.9120 - learning_rate: 9.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9956 - class_output1_loss: 0.0174 - class_output2_accuracy: 0.9981 - class_output2_loss: 0.0076 - loss: 0.0250 - val_class_output1_accuracy: 0.8789 - val_class_output1_loss: 0.5568 - val_class_output2_accuracy: 0.9269 - val_class_output2_loss: 0.3604 - val_loss: 0.9179 - learning_rate: 2.7000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - class_output1_accuracy: 0.9961 - class_output1_loss: 0.0152 - class_output2_accuracy: 0.9978 - class_output2_loss: 0.0076 - loss: 0.0227 - val_class_output1_accuracy: 0.8795 - val_class_output1_loss: 0.5588 - val_class_output2_accuracy: 0.9278 - val_class_output2_loss: 0.3699 - val_loss: 0.9293 - learning_rate: 2.7000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m1562/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - class_output1_accuracy: 0.9967 - class_output1_loss: 0.0136 - class_output2_accuracy: 0.9978 - class_output2_loss: 0.0075 - loss: 0.0210\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - class_output1_accuracy: 0.9967 - class_output1_loss: 0.0136 - class_output2_accuracy: 0.9978 - class_output2_loss: 0.0075 - loss: 0.0210 - val_class_output1_accuracy: 0.8792 - val_class_output1_loss: 0.5696 - val_class_output2_accuracy: 0.9270 - val_class_output2_loss: 0.3747 - val_loss: 0.9449 - learning_rate: 2.7000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - class_output1_accuracy: 0.9967 - class_output1_loss: 0.0130 - class_output2_accuracy: 0.9982 - class_output2_loss: 0.0067 - loss: 0.0197 - val_class_output1_accuracy: 0.8811 - val_class_output1_loss: 0.5708 - val_class_output2_accuracy: 0.9268 - val_class_output2_loss: 0.3729 - val_loss: 0.9442 - learning_rate: 8.1000e-06\n"
          ]
        }
      ],
      "source": [
        "# Creazione e valutazione del modello\n",
        "model_instance = build_model()\n",
        "assess_model(model_instance)\n",
        "\n",
        "# Aggiustamento dinamico del Learning Rate\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=3, # Epoche senza miglioramenti necessarie per diminuire LR\n",
        "    verbose=1,\n",
        "    factor=0.3, # Fattore di diminuzione LR\n",
        "    min_lr=1e-6 # Valore minimo LR\n",
        ")\n",
        "\n",
        "# Training del modello\n",
        "training_history = model_instance.fit(\n",
        "    cifar10_x_train, # Utilizziamo dati di training\n",
        "    {\n",
        "        'class_output1': tf.keras.utils.to_categorical(\n",
        "            np.where(cifar10_y_train < 5, cifar10_y_train, 0), num_classes=5\n",
        "        ),\n",
        "        'class_output2': tf.keras.utils.to_categorical(\n",
        "            np.where(cifar10_y_train >= 5, cifar10_y_train - 5, 0), num_classes=5\n",
        "        )\n",
        "    },\n",
        "    epochs=20, #Ripetizioni\n",
        "    batch_size=32,\n",
        "    validation_data=(\n",
        "        cifar10_x_test, # Dati di validazione/test\n",
        "        {\n",
        "            'class_output1': tf.keras.utils.to_categorical(\n",
        "                np.where(cifar10_y_test < 5, cifar10_y_test, 0), num_classes=5\n",
        "            ),\n",
        "            'class_output2': tf.keras.utils.to_categorical(\n",
        "                np.where(cifar10_y_test >= 5, cifar10_y_test - 5, 0), num_classes=5\n",
        "            )\n",
        "        }\n",
        "    ),\n",
        "    callbacks=[lr_scheduler]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7usBI88dje70"
      },
      "source": [
        "let us repeat the evaluation ten times, and comput the standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFu8iEt9jdZA",
        "outputId": "1c11f296-7cc2-48e9-953e-aac1e047bc12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution number 1/10\n",
            "Execution number 2/10\n",
            "Execution number 3/10\n",
            "Execution number 4/10\n",
            "Execution number 5/10\n",
            "Execution number 6/10\n",
            "Execution number 7/10\n",
            "Execution number 8/10\n",
            "Execution number 9/10\n",
            "Execution number 10/10\n",
            "Valutazione delle accuracies: [0.9039500057697296, 0.9039500057697296, 0.9039500057697296, 0.9039500057697296, 0.9039500057697296, 0.9039500057697296, 0.9039500057697296, 0.9039500057697296, 0.9039500057697296, 0.9039500057697296]\n",
            "Accuracy media: 0.9040\n",
            "Standard Deviation: 0.0000\n"
          ]
        }
      ],
      "source": [
        "all_accuracies = []\n",
        "random_indices = np.random.choice(cifar10_x_test.shape[0], 10000, replace=False) # Generazione dei 10000 input dai dati di test\n",
        "\n",
        "# Eseguiamo il calcolo 10 volte\n",
        "for run in range(10):\n",
        "    print(f\"Execution number {run + 1}/10\")\n",
        "    np.random.seed(run)\n",
        "\n",
        "    sampled_x = cifar10_x_test[random_indices]\n",
        "\n",
        "    sampled_y1 = tf.keras.utils.to_categorical(\n",
        "        np.where(cifar10_y_test[random_indices] < 5, cifar10_y_test[random_indices], 0),\n",
        "        num_classes=5\n",
        "    )\n",
        "    sampled_y2 = tf.keras.utils.to_categorical(\n",
        "        np.where(cifar10_y_test[random_indices] >= 5, cifar10_y_test[random_indices] - 5, 0),\n",
        "        num_classes=5\n",
        "    )\n",
        "\n",
        "    eval_results = model_instance.evaluate(\n",
        "        sampled_x,\n",
        "        {'class_output1': sampled_y1, 'class_output2': sampled_y2},\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    acc_group1 = eval_results[3]\n",
        "    acc_group2 = eval_results[4]\n",
        "    avg_acc = (acc_group1 + acc_group2) / 2\n",
        "    all_accuracies.append(avg_acc)\n",
        "\n",
        "# Calcolo e output risultati\n",
        "accuracy_mean = np.mean(all_accuracies)\n",
        "accuracy_std = np.std(all_accuracies)\n",
        "\n",
        "print(\"Valutazione delle accuracies:\", all_accuracies)\n",
        "print(f\"Accuracy media: {accuracy_mean:.4f}\")\n",
        "print(f\"Standard Deviation: {accuracy_std:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1yTRAzn4i9g"
      },
      "source": [
        "# Cosa consegnare\n",
        "\n",
        "Come di consueto, dovete consegnare un singolo notebook che deve essere eseguibile su colab. Il notebook deve essere adeguatamente commentato a contenere una traccia completa del training, come anche il calcolo della accuratezza secondo le direttive date sopra.\n",
        "\n",
        "#Buon lavoro!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}